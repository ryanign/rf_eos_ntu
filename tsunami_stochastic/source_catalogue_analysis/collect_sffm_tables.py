"""
Ryan Pranantyo
EOS, May 2025

script to collect SFFM tables generated by RPTHA code,
the collected tables will be then used for next analyses
"""
import os, sys
import numpy as np
import pandas as pd
import geopandas as gpd
import argparse
import glob
from pathlib import Path

def clean_up_sffm__slow(sffm_df, grid_gdf):
    print("cleaning up SFFM model")
    df = pd.DataFrame()
    unit_source_index = (np.arange(len(grid_gdf))+1).astype(int)
    additional = ['target_lon', 'target_lat', 'Mw', 'physical_corner_wavenumber_x', 'physical_corner_wavenumber_y', 'sourcename']
    df['unit_source_index'] = np.hstack([unit_source_index, additional])
    for src in sffm_df.index:
        flt_index_str = sffm_df.event_index_string[src]
        flt_slip_str  = sffm_df.event_slip_string[src]
        flt_index = list(map(str, flt_index_str.split('-')[:-1]))
        flt_slip  = list(map(str, flt_slip_str.split('_')[:-1]))
        tmp_df = pd.DataFrame(data = {'unit_source_index' : flt_index,
                                      f'unit_source_slip__{src}'  : flt_slip})
        tmp_df.loc[-1] = ['target_lon', sffm_df['target_lon'][src]]
        tmp_df.loc[-2] = ['target_lat', sffm_df['target_lat'][src]]
        tmp_df.loc[-3] = ['Mw', sffm_df['Mw'][src]]
        tmp_df.loc[-4] = ['physical_corner_wavenumber_x', sffm_df['physical_corner_wavenumber_x'][src]]
        tmp_df.loc[-5] = ['physical_corner_wavenumber_y', sffm_df['physical_corner_wavenumber_y'][src]]
        tmp_df.loc[-6] = ['sourcename', sffm_df['sourcename'][src]]
        df = pd.merge(df, tmp_df, on='unit_source_index', how='left')
    return df, grid_gdf

def clean_up_sffm(sffm_df, grid_gdf):
    print("merging into one big SFFM DataFrame")
    unit_source_index = (np.arange(len(grid_gdf))+1).astype(int)

    # initial DataFrame
    meta_rows = [
            ['target_lon'] + [np.nan] * len(unit_source_index),
            ['target_lat'] + [np.nan] * len(unit_source_index),
            ['Mw'] + [np.nan] * len(unit_source_index),
            ['physical_corner_wavenumber_x'] + [np.nan] * len(unit_source_index),
            ['physical_corner_wavenumber_y'] + [np.nan] * len(unit_source_index),
            ['sourcename'] + [np.nan] * len(unit_source_index),
            ]

    # start with base DF
    df_base = pd.DataFrame({'unit_source_index' : unit_source_index})
    all_dfs = [df_base]

    # start the loop
    for src in sffm_df.index:
        # get slip data
        flt_index_str = sffm_df.event_index_string[src]
        flt_slip_str  = sffm_df.event_slip_string[src]
        flt_index = list(map(int, flt_index_str.split('-')[:-1]))
        flt_slip  = list(map(float, flt_slip_str.split('_')[:-1]))
        #flt_index_str = sffm_df.at[src, 'event_index_string'],
        #flt_slip_str = sffm_df.at[src, 'event_slip_string']
        #flt_index = flt_index_str.split('-')[:-1]
        #flt_slip = flt_slip_str.splot('_')[:-1]

        tmp_dict = {
                'unit_source_index' : flt_index,
                f'unit_source_slip__{src}' : flt_slip,
        }

        tmp_df = pd.DataFrame(tmp_dict)

        # add meta information rows
        meta_data = [
                ['target_lon', sffm_df.at[src, 'target_lon']],
                ['target_lat', sffm_df.at[src, 'target_lat']],
                ['Mw', sffm_df.at[src, 'Mw']],
                ['physical_corner_wavenumber_x', sffm_df.at[src, 'physical_corner_wavenumber_x']],
                ['physical_corner_wavenumber_y', sffm_df.at[src, 'physical_corner_wavenumber_y']],
                ['sourcename', sffm_df.at[src, 'sourcename']]
                ]

        meta_df = pd.DataFrame(meta_data, columns = ['unit_source_index', f'unit_source_slip__{src}'])

        # combine slips and meta rows
        combined_df = pd.concat([tmp_df, meta_df], ignore_index = True)
        all_dfs.append(combined_df)

    # final merge
    df = df_base
    for d in all_dfs[1:]:
        df = df.merge(d, on='unit_source_index', how='left')

    return df

def collect_sffm_original(tables):
    print(len(tables))
    df = pd.DataFrame()
    for ii in range(len(tables)):
        df = pd.concat([df, pd.read_csv(tables[ii])], axis = 0, ignore_index = True)
    df = df.drop(columns = ['event_id'])
    df = df.sample(frac=1).reset_index(drop = True)
    print(f" shuffle the list ...")
    print(df)
    return df

    
    


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--Mw_target", type = float,
                        default = 8.1,
                        help = "SFFM tables to be collected")
    parser.add_argument("--path_to_SFFM", type = str,
                        default = "/home/ignatius.pranantyo/Tsunamis/Stochastic__Sumatera_Java/PUSGEN2017__Segmentatations/OUTPUTS__Slab2__Jawa/SourceCombinations__Mw8_5_to_8_7/stochastic_slips__SLAB2__Jawa")
    parser.add_argument("--sourcename", type = str,
                        default = "SLAB2__Jawa",
                        help = "Name of the sourcename")
    parser.add_argument("--grid_source", type = str,
                        default = "/home/ignatius.pranantyo/Tsunamis/Stochastic__Sumatera_Java/PUSGEN2017__Segmentatations/OUTPUTS__Slab2__Jawa/unit_source_grid/SLAB2__Jawa.shp",
                        help = "a polygon shapefile generated when generating unit_source using RPTHA")
    args = parser.parse_args()

    ### Mw to collect
    Mw = args.Mw_target

    ### sffm_path
    sffm_path = Path(args.path_to_SFFM)

    ### create a new folder to save the collected SFFM tables
    collected_sffm_path = Path(os.path.join(sffm_path, "SFFM_tables__collection"))
    collected_sffm_path.mkdir(exist_ok = True)
    
    ### unit source filename
    unit_f = os.path.join(sffm_path, f"unit_source_grid_raster_filename_index__{args.sourcename}.csv")
    unit_df = pd.read_csv(unit_f)
    unit_df = unit_df.rename(
            columns = {
                'Unnamed: 0' : 'unit_source_index',
                'x'          : 'unit_source_filename'}
            )

    ### read SFFM grid polygon used
    grid_source = Path(args.grid_source)
    grid_gdf = gpd.read_file(grid_source)
    #re-order index of the SFFM to match SFFM tables
    grid_gdf = grid_gdf.sort_values(by=['alngst_', 'dwndp_n']).reset_index()
    #to make same column name
    grid_gdf['unit_source_index'] = (np.arange(len(grid_gdf))+1).astype(int)
    grid_gdf = grid_gdf.drop(columns=['index'])
    grid_fout = os.path.join(collected_sffm_path, f"final__{grid_source.name}")
    grid_gdf.to_file(grid_fout)

    ### create a list of SFFM table input files
    print(f"  going to collect original SFFM tables")
    tables = glob.glob(os.path.join(sffm_path, f"stochastic_sources__Mw_{Mw:.6f}__Lon*__table.csv"))
    df = collect_sffm_original(tables)
    clean_df, grid = clean_up_sffm(df, grid_gdf)

    clean_df = pd.concat([clean_df, unit_df], axis = 1)
    fout = os.path.join(collected_sffm_path, f"stochastic_sources__Mw_{Mw:.6f}__table.csv")
    clean_df.to_csv(fout)





    sys.exit()

    """
    DONE
    DONE
    DONE
    """
        



